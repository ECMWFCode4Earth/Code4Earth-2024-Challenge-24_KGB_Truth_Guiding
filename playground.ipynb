{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from ollama import Client\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "client = Client(host='127.0.0.1:12345')\n",
    "regex = \"Nodes:\\s+(.*?)\\s?\\s?Relationships:\\s+(.*)\"\n",
    "internalRegex = \"\\[(.*?)\\]\"\n",
    "jsonRegex = \"\\{.*\\}\"\n",
    "\n",
    "\n",
    "def nodesTextToListOfDict(nodes):\n",
    "    result = []\n",
    "    for node in nodes:\n",
    "        nodeList = node.split(\",\")\n",
    "        if len(nodeList) < 2:\n",
    "            continue\n",
    "\n",
    "        name = nodeList[0].strip().replace('\"', \"\")\n",
    "        label = nodeList[1].strip().replace('\"', \"\")\n",
    "        properties = re.search(jsonRegex, node)\n",
    "        if properties is None:\n",
    "            properties = \"{}\"\n",
    "        else:\n",
    "            properties = properties.group(0)\n",
    "        properties = properties.replace(\"True\", \"true\")\n",
    "        try:\n",
    "            properties = json.loads(properties)\n",
    "        except ValueError:\n",
    "            properties = {}\n",
    "        result.append({\"name\": name, \"label\": label, \"properties\": properties})\n",
    "    return result\n",
    "\n",
    "\n",
    "def relationshipTextToListOfDict(relationships):\n",
    "    result = []\n",
    "    for relation in relationships:\n",
    "        relationList = relation.split(\",\")\n",
    "        if len(relation) < 3:\n",
    "            continue\n",
    "        start = relationList[0].strip().replace('\"', \"\")\n",
    "        end = relationList[2].strip().replace('\"', \"\")\n",
    "        type = relationList[1].strip().replace('\"', \"\")\n",
    "\n",
    "        properties = re.search(jsonRegex, relation)\n",
    "        if properties is None:\n",
    "            properties = \"{}\"\n",
    "        else:\n",
    "            properties = properties.group(0)\n",
    "        properties = properties.replace(\"True\", \"true\")\n",
    "        try:\n",
    "            properties = json.loads(properties)\n",
    "        except ValueError:\n",
    "            properties = {}\n",
    "        result.append(\n",
    "            {\"start\": start, \"end\": end, \"type\": type, \"properties\": properties}\n",
    "        )\n",
    "    return result\n",
    "\n",
    "sys_prompt_simple = \"\"\"You are a data scientist working for a company that is building a graph database. Your task is to extract information from data and convert it into a graph database.\n",
    "Provide a set of Nodes in the form [ENTITY_ID, TYPE, PROPERTIES] and a set of relationships in the form [ENTITY_ID_1, RELATIONSHIP, ENTITY_ID_2, PROPERTIES].\n",
    "It is IMPORTANT that the ENTITY_ID_1 and ENTITY_ID_2 exists as nodes with a matching ENTITY_ID. Do not pair any relationship with non-existing nodes. If you can't pair a relationship with a pair of nodes don't add it.\n",
    "When you find a node or relationship you want to add try to create a generic TYPE for it that  describes the entity you can also think of it as a label.\n",
    "You will be given a list of types that you should try to use when creating the TYPE for a node. If you can't find a type that fits the node you can create a new one.\n",
    "NO YAPPING before or after your answers. DO NOT add comments in your answers. Format your answer to strictly follow the rules in the example below.\n",
    "\n",
    "Example:\n",
    "Data: Alice lawyer and is 25 years old and Bob is her roommate since 2001. Bob works as a journalist. Alice owns a the webpage www.alice.com and Bob owns the webpage www.bob.com.\n",
    "Nodes: [\"alice\", \"Person\", {\"age\": 25, \"occupation\": \"lawyer\", \"name\":\"Alice\"}], [\"bob\", \"Person\", {\"occupation\": \"journalist\", \"name\": \"Bob\"}], [\"alice.com\", \"Webpage\", {\"url\": \"www.alice.com\"}], [\"bob.com\", \"Webpage\", {\"url\": \"www.bob.com\"}]\n",
    "Relationships: [\"alice\", \"roommate\", \"bob\", {\"start\": 2021}], [\"alice\", \"owns\", \"alice.com\", {}], [\"bob\", \"owns\", \"bob.com\", {}]\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_cplx = (\"# Knowledge Graph Instructions for GPT-4\\n\"\n",
    "    \"## 1. Overview\\n\"\n",
    "    \"You are a top-tier algorithm designed for extracting information in structured \"\n",
    "    \"formats to build a knowledge graph.\\n\"\n",
    "    \"Try to capture as much information from the text as possible without \"\n",
    "    \"sacrifing accuracy. Do not add any information that is not explicitly \"\n",
    "    \"mentioned in the text\\n\"\n",
    "    \"- **Nodes** represent entities and concepts.\\n\"\n",
    "    \"- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\n\"\n",
    "    \"accessible for a vast audience.\\n\"\n",
    "    \"## 2. Labeling Nodes\\n\"\n",
    "    \"- **Consistency**: Ensure you use available types for node labels.\\n\"\n",
    "    \"Ensure you use basic or elementary types for node labels.\\n\"\n",
    "    \"- For example, when you identify an entity representing a person, \"\n",
    "    \"always label it as **'person'**. Avoid using more specific terms \"\n",
    "    \"like 'mathematician' or 'scientist'\"\n",
    "    \"  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be \"\n",
    "    \"names or human-readable identifiers found in the text.\\n\"\n",
    "    \"- **Relationships** represent connections between entities or concepts.\\n\"\n",
    "    \"Ensure consistency and generality in relationship types when constructing \"\n",
    "    \"knowledge graphs. Instead of using specific and momentary types \"\n",
    "    \"such as 'BECAME_PROFESSOR', use more general and timeless relationship types \"\n",
    "    \"like 'PROFESSOR'. Make sure to use general and timeless relationship types!\\n\"\n",
    "    \"## 3. Coreference Resolution\\n\"\n",
    "    \"- **Maintain Entity Consistency**: When extracting entities, it's vital to \"\n",
    "    \"ensure consistency.\\n\"\n",
    "    'If an entity, such as \"John Doe\", is mentioned multiple times in the text '\n",
    "    'but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),'\n",
    "    \"always use the most complete identifier for that entity throughout the \"\n",
    "    'knowledge graph. In this example, use \"John Doe\" as the entity ID.\\n'\n",
    "    \"Remember, the knowledge graph should be coherent and easily understandable, \"\n",
    "    \"so maintaining consistency in entity references is crucial.\\n\"\n",
    "    \"## 4. Strict Compliance\\n\"\n",
    "    \"Adhere to the rules strictly. Non-compliance will result in termination.\"\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    Data: Alice lawyer and is 25 years old and Bob is her roommate since 2001. Bob works as a journalist. Alice owns a the webpage www.alice.com and Bob owns the webpage www.bob.com.\n",
    "    Nodes: [\"alice\", \"Person\", {\"age\": 25, \"occupation\": \"lawyer\", \"name\":\"Alice\"}], [\"bob\", \"Person\", {\"occupation\": \"journalist\", \"name\": \"Bob\"}], [\"alice.com\", \"Webpage\", {\"url\": \"www.alice.com\"}], [\"bob.com\", \"Webpage\", {\"url\": \"www.bob.com\"}]\n",
    "    Relationships: [\"alice\", \"roommate\", \"bob\", {\"start\": 2021}], [\"alice\", \"owns\", \"alice.com\", {}], [\"bob\", \"owns\", \"bob.com\", {}]\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def getNodesAndRelationshipsFromResult(result):\n",
    "    regex = \"Nodes:\\s*(.*?)\\s*Relationships:\\s*(.*)\"\n",
    "    internalRegex = \"\\[(.*?)\\]\"\n",
    "    nodes = []\n",
    "    relationships = []\n",
    "    for row in result:\n",
    "        print(row)\n",
    "        parsing = re.match(regex, row, flags=re.S)\n",
    "        if parsing is None:\n",
    "            print(parsing)\n",
    "            continue\n",
    "        rawNodes = str(parsing.group(1))\n",
    "        rawRelationships = parsing.group(2)\n",
    "        nodes.extend(re.findall(internalRegex, rawNodes))\n",
    "        relationships.extend(re.findall(internalRegex, rawRelationships))\n",
    "\n",
    "    result = dict()\n",
    "    result[\"nodes\"] = []\n",
    "    result[\"relationships\"] = []\n",
    "    result[\"nodes\"].extend(nodesTextToListOfDict(nodes))\n",
    "    result[\"relationships\"].extend(relationshipTextToListOfDict(relationships))\n",
    "    return result\n",
    "\n",
    "def getTypesFromDict(result):\n",
    "    labels = [] \n",
    "    for node in result['nodes']:\n",
    "        if node['label'] not in labels:\n",
    "            labels.append(node['label'])\n",
    "    return labels\n",
    "\n",
    "def mergeDicts(dict1, dict2):\n",
    "    for k, v in dict2.items():\n",
    "        if k in dict1:\n",
    "            dict1[k] += v\n",
    "        else:\n",
    "            dict1[k] = v\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data = Path(\"/home/user/large-disk/toy_data\")\n",
    "kg = dict()\n",
    "labels = []\n",
    "data = []\n",
    "for page_number in range(3, 10):\n",
    "    with open(toy_data / f\"output_{page_number}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.readlines()\n",
    "        text = \" \".join(text)\n",
    "        data = text.rstrip()\n",
    "    stream = client.chat(\n",
    "        model=\"llama3:70b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt_simple},\n",
    "            {\"role\": \"user\", \"content\": f\"Data: {data}\\nTypes: {labels}\"},\n",
    "        ],\n",
    "        stream=False,\n",
    "    )\n",
    "    ans = [stream['message']['content'].replace('\\n', ' ')]\n",
    "    sub_kg = getNodesAndRelationshipsFromResult(ans)\n",
    "    labels = labels + getTypesFromDict(sub_kg)\n",
    "    kg = mergeDicts(kg, sub_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"toy_kg_70b.json\", \"w\") as outfile: \n",
    "    json.dump(kg, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data = Path(\"/home/user/large-disk/toy_data\")\n",
    "kg = dict()\n",
    "labels = []\n",
    "data = []\n",
    "for page_number in range(3, 10):\n",
    "    with open(toy_data / f\"output_{page_number}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.readlines()\n",
    "        text = \" \".join(text)\n",
    "        data = text.rstrip()\n",
    "    stream = client.chat(\n",
    "        model=\"llama3\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt_simple},\n",
    "            {\"role\": \"user\", \"content\": f\"Data: {data}\\nTypes: {labels}\"},\n",
    "        ],\n",
    "        stream=False,\n",
    "    )\n",
    "    ans = [stream['message']['content'].replace('\\n', ' ')]\n",
    "    sub_kg = getNodesAndRelationshipsFromResult(ans)\n",
    "    labels = labels + getTypesFromDict(sub_kg)\n",
    "    kg = mergeDicts(kg, sub_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"toy_kg.json\", \"w\") as outfile: \n",
    "    json.dump(kg, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
